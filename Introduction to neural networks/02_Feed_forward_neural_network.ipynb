{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "02. Feed forward neural network.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tillaczel/Machin-learning-workshop/blob/master/Introduction%20to%20neural%20networks/02_Feed_forward_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTNnIFqkJrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAhbS4YdkJre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class network():\n",
        "\n",
        "    def __init__(self,layers,activations,learning_rate):\n",
        "        self.layers = layers\n",
        "        self.activations = activations\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        self.weights = [None]*(len(self.layers)-1)\n",
        "        \n",
        "        for layer in range(len(self.layers)-1):\n",
        "            self.weights[layer] = np.random.randn(self.layers[layer+1],self.layers[layer]+1)*np.sqrt(1/(self.layers[layer]+1))\n",
        "            \n",
        "    def actiovation_functions(self,function,z):\n",
        "        if function == 'linear':\n",
        "            return z\n",
        "        elif function == 'ReLu':\n",
        "            return np.maximum(0.1*z,z)\n",
        "            \n",
        "    def actiovation_functions_derivative(self,function,X):\n",
        "        X = np.copy(X)\n",
        "        if function == 'linear':\n",
        "            return np.ones(X.shape)\n",
        "        elif function == 'ReLu':\n",
        "            X[X<=0] = 0.1\n",
        "            X[X>0] = 1\n",
        "            return X\n",
        "            \n",
        "    def predict(self,X):\n",
        "        for layer in range(len(self.layers)-1):\n",
        "            X_ = np.concatenate((np.ones((X.shape[0],1)),X),axis=1)\n",
        "            z = np.transpose(np.dot(self.weights[layer],np.transpose(X_)))\n",
        "            a = self.actiovation_functions(self.activations[layer],z)\n",
        "            X = a\n",
        "        return X\n",
        "        \n",
        "    def train(self,X,Y,epoch):\n",
        "        for e in range(epoch):\n",
        "            # Forward\n",
        "            Z = [None]*(len(self.layers))\n",
        "            A = [None]*(len(self.layers))\n",
        "            A[0] = X\n",
        "            for layer in range(1,len(self.layers)):\n",
        "                X_ = np.concatenate((np.ones((A[layer-1].shape[0],1)),A[layer-1]),axis=1)\n",
        "                Z[layer] = np.transpose(np.dot(self.weights[layer-1],np.transpose(X_)))\n",
        "                A[layer] = self.actiovation_functions(self.activations[layer-1],Z[layer])\n",
        "\n",
        "            # Backward\n",
        "            dZ = [None]*(len(self.layers)-1)\n",
        "            dA = [None]*(len(self.layers)-1)\n",
        "            dW = [None]*(len(self.layers)-1)\n",
        "            dA[-1] = A[-1]-Y\n",
        "            for layer in range(len(self.layers)-1,0,-1):\n",
        "                dZ[layer-1] = np.multiply(dA[layer-1],self.actiovation_functions_derivative(self.activations[layer-1],Z[layer]))\n",
        "                A_ = np.concatenate((np.ones((A[layer-1].shape[0],1)),A[layer-1]),axis=1)\n",
        "                dW[layer-1] =  np.einsum('ab,ac->abc', dZ[layer-1], A_)/self.layers[layer]\n",
        "                if -1 < layer-2:\n",
        "                    dA[layer-2] = np.sum(dW[layer-1],axis=1)[:,1:]\n",
        "            \n",
        "            # Update\n",
        "            for layer in range(len(self.layers)-1):\n",
        "                self.weights[layer] += -self.learning_rate*np.mean(dW[layer],axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3us-rq6EkJrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.random.rand(100,2)*2-1\n",
        "Y = (np.multiply(X[:,0],X[:,1])/np.abs(np.multiply(X[:,0],X[:,1]))/2+0.5).reshape(X.shape[0],1)\n",
        "model = network([2,20,1],['ReLu','linear'],0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "M5_Y_FsQkJsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model.weights)\n",
        "# print(model.predict(X))\n",
        "model.train(X,Y,100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_xG2abJkJss",
        "colab_type": "code",
        "outputId": "8eddb744-9b8a-4942-f5dd-7d4c4ddfb26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.predict(X)-Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.12933451]\n",
            " [ 0.12018234]\n",
            " [ 0.08161776]\n",
            " [-0.58433093]\n",
            " [-0.83516786]\n",
            " [ 0.60430828]\n",
            " [-0.2162776 ]\n",
            " [ 0.11231674]\n",
            " [ 0.49846396]\n",
            " [-0.69466583]\n",
            " [ 0.05530461]\n",
            " [-0.23113887]\n",
            " [-0.17526843]\n",
            " [ 0.33411207]\n",
            " [-0.04333216]\n",
            " [-0.56340005]\n",
            " [-0.60073817]\n",
            " [-0.41145579]\n",
            " [ 0.35953042]\n",
            " [ 0.19795376]\n",
            " [ 0.61946894]\n",
            " [-0.26346419]\n",
            " [-0.44748154]\n",
            " [ 0.23595622]\n",
            " [ 0.42670621]\n",
            " [ 0.31476326]\n",
            " [ 0.15002256]\n",
            " [-0.43450092]\n",
            " [-0.58650262]\n",
            " [-0.51257961]\n",
            " [-0.02155095]\n",
            " [ 0.08796074]\n",
            " [-0.29642526]\n",
            " [-0.17220605]\n",
            " [ 0.53109185]\n",
            " [-0.31575585]\n",
            " [ 0.44140287]\n",
            " [ 0.08231962]\n",
            " [-0.11745367]\n",
            " [-0.76293633]\n",
            " [ 0.34540413]\n",
            " [ 0.46231139]\n",
            " [-0.75680211]\n",
            " [ 0.29877256]\n",
            " [ 0.23499462]\n",
            " [-0.28668294]\n",
            " [-0.23915083]\n",
            " [-0.25883532]\n",
            " [ 0.11877564]\n",
            " [ 0.01265172]\n",
            " [-0.22840873]\n",
            " [ 0.4563234 ]\n",
            " [-0.42333599]\n",
            " [ 0.27856174]\n",
            " [ 0.12307693]\n",
            " [ 0.13460287]\n",
            " [ 0.21202505]\n",
            " [-0.37199312]\n",
            " [ 0.21649278]\n",
            " [-0.60487114]\n",
            " [ 0.21940957]\n",
            " [ 0.09532016]\n",
            " [ 0.55831541]\n",
            " [-0.18485208]\n",
            " [ 0.26466984]\n",
            " [-0.04389694]\n",
            " [-0.17811787]\n",
            " [-0.07886009]\n",
            " [-0.33246795]\n",
            " [-0.18106792]\n",
            " [ 0.05821596]\n",
            " [ 0.30907658]\n",
            " [ 0.58844253]\n",
            " [ 0.06395501]\n",
            " [ 0.06057254]\n",
            " [ 0.20959534]\n",
            " [ 0.26968108]\n",
            " [-0.81821509]\n",
            " [ 0.6450084 ]\n",
            " [-0.49981625]\n",
            " [-0.31426733]\n",
            " [ 0.29763972]\n",
            " [ 0.24057474]\n",
            " [-0.18271423]\n",
            " [ 0.39780387]\n",
            " [ 0.10777094]\n",
            " [-0.43187964]\n",
            " [ 0.51908827]\n",
            " [ 0.15395929]\n",
            " [ 0.35374653]\n",
            " [ 0.25673842]\n",
            " [ 0.23346227]\n",
            " [ 0.1984778 ]\n",
            " [ 0.41651493]\n",
            " [-0.04295469]\n",
            " [ 0.48285997]\n",
            " [-0.30754549]\n",
            " [-0.1606586 ]\n",
            " [ 0.31996729]\n",
            " [-0.35310448]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHOSfyUfkJs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}